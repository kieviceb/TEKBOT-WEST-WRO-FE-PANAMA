# TEKBOT WEST's readme <img src="https://upload.wikimedia.org/wikipedia/commons/a/ab/Flag_of_Panama.svg" alt="Bandera de Panam√°" width="30"/>

<p align="center">
  <img src="https://github.com/user-attachments/assets/be75ac88-018e-48ce-b09f-6da08b648245" alt="TEKBOT (1)">
</p>

[![Instagram](https://img.shields.io/badge/Instagram-%23E9805F.svg?style=for-the-badge&logo=Instagram&logoColor=white)](https://www.instagram.com/tekbot_lab?utm_source=ig_web_button_share_sheet&igsh=ZDNlZDc0MzIxNw==)
[![Facebook](https://img.shields.io/badge/YouTube-%23E4445F.svg?style=for-the-badge&logo=Youtube&logoColor=white)](https://www.youtube.com/@TEKBOT_LAB)

This is the official repository for TEKBOT WEST, the team participating in the Panama WRO Regional phase to compete for a spot on the national team. Here you'll find everything related to the development of our robot as we strive towards the national and international finals!


# Repo's folder structure/overview
```
üì¶ TEKBOT-WEST-WRO-FE
‚îú‚îÄ‚îÄ üìÅ 3D_printables # 3D models ready for printing robot components
‚îú‚îÄ‚îÄ üìÅ schemes # Wiring and schematic diagram
‚îú‚îÄ‚îÄ üìÅ src # Source code for robot control and challenge algorithms
‚îú‚îÄ‚îÄ üìÅ team photos # Photos of the team 
‚îú‚îÄ‚îÄ üìÅ vehicle photos # Pictures of the robot at different views
‚îú‚îÄ‚îÄ üìÅ video # Video of testing competition runs
‚îú‚îÄ‚îÄ üìÑ README.md # Main project documentation
```
---
  
## Meet the team üë®‚Äçüíª
<p align="center">
  <img src="https://github.com/user-attachments/assets/bbfb9286-652d-4064-b1f4-a33967fa7d1e" width="700">
</p>

## üë§ Luis Hidalgo  
### Age: 16  
Luis is the team‚Äôs **electrician and hardware specialist**. He handles wiring, sensors, and all things related to power and circuitry. Luis brings hands-on experience from previous **WRO competitions**, contributing to the robot's reliability and performance.

## üë©‚Äçüíª Ericka Ceballos  
### Age: 18  
Ericka is the team‚Äôs **programmer**, responsible for writing and debugging the robot's code. She ensures that the robot can make real-time decisions and execute tasks with precision. Ericka has participated in **WRO** and brings her technical and problem-solving skills to every challenge.

## üé® Patrick Sutherland  
### Age: 17  
Patrick serves as the **designer** of the team. He focuses on the mechanical layout and overall functionality of the robot, balancing creativity with engineering. Patrick is also a returning **WRO participant**, constantly improving the robot's design through testing and iteration.

## üß† Our Coach ‚Äî Diego Delgado  
### Age: 25  
Diego is the team‚Äôs **coach and mentor**, guiding the team through strategy, planning, and technical reviews. He is the **founder of Tekbot**, an organization dedicated to promoting STEM and robotics education for children and young people. Diego is a **former WRO participant** himself and has also coached teams in **FRC**, offering a broad perspective and deep expertise in robotics education.

---
# Vehicle Photos üì∏

| Front           | Right       | Back      |
|:---------------:|:-----------:|:---------:|
| <img width="270" alt="front" src="https://github.com/user-attachments/assets/52ef1eb8-44c9-489f-9020-e1c41df86249"> |<img width="270" alt="front" src="https://github.com/user-attachments/assets/98f60e79-1afc-43a9-aa50-4e2e825715e4"> |  <img width="270" alt="front" src="https://github.com/user-attachments/assets/6c593234-e3ec-4686-a9a8-bdd1bfbeefac"> |
| Left          | Top       | Bottom     |
|<img width="270" alt="front" src="https://github.com/user-attachments/assets/b835d64c-79fb-4abb-b9a4-92445bec3d5b">| <img width="270" alt="front" src="https://github.com/user-attachments/assets/837ce766-5ce4-4726-8e1b-41b85ca31dbd"> | <img width="270" alt="front" src="https://github.com/user-attachments/assets/db67a2cb-4798-4c9f-8c6b-0a57b5aee964">|
<br>

# Components üß±
A list of all the electrical and mechanical components on the robot.

| <img src="https://github.com/user-attachments/assets/719a51d8-4b14-402d-a462-ba1e4b071c2c" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/3641b928-34c5-4d97-861c-fa08d40c9faa" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/3d5651d3-c8fe-4935-9561-6ca9d9c87a76" alt="Alt 1" width="200"/> | 
| :------------: |:-------------:| :------------:|
|[Raspberry Pi 5 - 8GB RAM x1](https://store-usa.arduino.cc/products/arduino-nano?srsltid=AfmBOooU4-IrktQwXymxJgaV7MZPj3cBWDjg6AjQwBmYoQw8es2bz9ex)|[Microsoft LifeCam HD-3000 x1](https://a.co/d/42jYlB6)|[L298N motor driver x1](https://www.steren.com.pa/tarjeta-para-control-de-motores-cc-l298n.html)|
| <img src="https://github.com/user-attachments/assets/5b0ffc5d-ce02-4620-9849-15fdce566702" width="200"/> | <img src="https://github.com/user-attachments/assets/d4170adc-23b9-446f-bac0-1c50b966e00f" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/b9cfe245-e774-4e4c-aed9-0e2c7445bf3c" alt="Alt 1" width="200"/> |
| [Arduino NANO RP2040 x1](https://a.co/d/9mUTqVe) |[FUNDUINO kit chassis x1](https://a.co/d/fpJSHg1)|[INIU Slim 10,000mAh Power Bank x1](https://a.co/d/1patlqb) |
| <img src="https://github.com/user-attachments/assets/8002e73e-910a-462e-b991-5cd5c858e316" width="200"/> |<img src="https://github.com/user-attachments/assets/77157511-58ff-4ee8-9977-d3b53d906af6" alt="Alt 1" width="200"/>| <img src="https://github.com/user-attachments/assets/86d8bf70-708b-426f-896a-9283a74d13df" alt="Alt 1" width="200"/> |
|[Jumper wires](https://a.co/d/cw9IdJk)|[MG996R High Torque Metal Gear Servo x1](https://a.co/d/cRVAc0u)|[STEREN Li-ion 2800 mAh Rechargeable Battery x3](https://www.steren.com.pa/bateria-recargable-li-ion-2800-mah-tipo-18650-1.html)|
| <img src="https://github.com/user-attachments/assets/e9f54336-7c3e-4f5c-9fd6-187f679f36c4" width="200"/> |<img src="https://github.com/user-attachments/assets/9070d3fd-e59f-4762-a41c-219a8f243521" alt="Alt 1" width="200"/>| <img src="https://github.com/user-attachments/assets/e4f5aa32-4f95-4007-bf7e-19fbd9c0b517" alt="Alt 1" width="200"/> |
|[Infrared Proximity Distance Sensor x3](https://a.co/d/d245jBL)|[Cable Clamp Connectors](https://a.co/d/cV5jVKI)|[Silicone Hook Up Wire](https://a.co/d/fEKUibh)|
| <img src="https://github.com/user-attachments/assets/c4632267-e417-4f33-bfa0-a858d9f1e28e" width="200"/> |<img src="(https://github.com/user-attachments/assets/dd5c7b13-b8ad-4aa0-9481-8411c9bf2b1a" alt="Alt 1" width="200"/>| <img src="https://github.com/user-attachments/assets/72f660f8-0134-4bb3-aa97-c8b0ae3c5f5a" alt="Alt 1" width="200"/> |
|[Mini breadboard x1](https://a.co/d/0logMX9)|[Push button x1](https://a.co/d/70cfCgl)|[ 10K ohm Resistor x1](https://a.co/d/dTNRWBD)|

> [!WARNING]
>
> Our robot has infrared sensors connected, but they are not used in this regional competition.  
> Activating them is planned as a future improvement.
>

# ‚ö°Circuit diagram

![1](https://github.com/user-attachments/assets/d847c053-dc1a-4490-90ae-936d9f6d7b5f)
> [!NOTE]
> For schematic diagram as well in fritzing and PNG format
> [SCHEMES](https://github.com/kieviceb/TEKBOT-WEST-WRO-FE/tree/main/schemes)

--- 

# Future Engineers Challenge Overview

The **WRO 2025 Future Engineers challenge** challenges teams to design and build a fully autonomous robot capable of navigating a dynamic and randomized racetrack. Using a combination of sensors, computer vision, and advanced control algorithms, the robot must adapt to changing obstacles, follow predefined driving rules, and demonstrate precise maneuvering skills.

### üìå Competition Format

- **üèÅ Open Challenge:**  
  The robot must complete **three (3) laps** around a track where obstacles and track elements are randomly placed, requiring real-time adaptation.

- **üö¶ Obstacle Challenge:**  
  The robot must detect and respond correctly to randomly positioned colored markers:  
  - üü• **Red signs** ‚Üí Robot must drive on the right side of the lane.  
  - üü© **Green signs** ‚Üí Robot must drive on the left side of the lane.

  After completing the laps, the robot must find a designated parking zone and perform a precise **parallel parking maneuver** within a confined space, adding an additional technical challenge.

### üìë Documentation Requirements

Each team is required to maintain a **public GitHub repository** documenting their engineering design process, technical decisions, robot design, and source code. This encourages transparency, collaboration, and learning within the robotics community.

### üèÜ Scoring & Evaluation

Teams are evaluated based on their robot‚Äôs **accuracy**, **speed**, and the quality of their **technical documentation**. Points are awarded to teams that effectively balance performance, adaptability to randomized conditions, and innovation in their approach. This challenge promotes not only technical skills in robotics and programming but also problem-solving, teamwork, and creative engineering.

---

> [!NOTE]
> For detailed rules and regulations (PANAMA ONLY), please refer to the official WRO Panama 2025 Future Engineers document:  
> [WRO 2025 Future Engineers Rules (PDF)](https://fundesteam.nyc3.cdn.digitaloceanspaces.com/FutureEngineers/WRO-2025-FE-Reglas%20Generales.pdf)

<br>


# ‚öôÔ∏è Mobility Management

Our robot's mobility system is divided into two main components: **movement** and **steering**.

### Movement
The robot uses a **DC motor** mounted at the rear, connected to a **shared rear axle** via a mechanical linkage. This ensures both rear wheels rotate together, complying with WRO rules. The motor shaft (D-shaft) is securely coupled to the axle for efficient torque transfer.

The motor is controlled by an **L298N motor driver**, which is connected directly to the **Raspberry Pi**. This allows the Pi to manage motor speed and direction based on real-time vision processing.

### Steering
For steering, we use the **MG996R metal gear servo motor**, known for its high torque and precision. The robot employs an **Ackermann steering system**, included in the Funduino kit, which mimics real vehicle steering geometry for smoother and more accurate turns.

The **Arduino Nano RP2040** receives steering commands from the Raspberry Pi and controls the servo motor accordingly.

# üîã Power Management

Our robot uses a well-organized power system to ensure stable and efficient energy distribution:

- A **power bank** supplies power to both the **Raspberry Pi** and the **Arduino Nano RP2040**, providing stable voltage and current to the main computing units.

- The **MG996R servo motor** is powered by the **5 volts** output from the **Raspberry Pi**, ensuring synchronized control and stable operation.

- The **Microsoft LifeCam HD-3000 webcam** connects to the **Raspberry Pi** via **USB**, receiving data and power directly through this interface.

- The **DC motor** is powered by **three STEREN Li-ion 2800 mAh rechargeable batteries** delivering **12 volts** through the **L298N driver**, allowing it to handle higher voltages and currents safely.

We are planning to upgrade the system by replacing the power bank with the **Geekworm Raspberry Pi Wide Input Voltage Power Management Module**, which will:

- Allow powering the Raspberry Pi and camera directly from lithium batteries with regulated voltage.
- Provide protected and reliable power delivery to all connected components.
- Help reduce overall weight and simplify cable management by removing the external power bank.

This upgrade aims to create a more compact, efficient, and reliable power system for the robot.

# üì° Robot Communication

Our robot implements a structured communication system between its two core processing units to ensure synchronized and reliable operation:

- The **Raspberry Pi** (SBC ‚Äì Single Board Computer) acts as the **master**. It is responsible for high-level tasks such as image processing, object detection, strategy decision-making, and general system coordination.

- The **Arduino Nano RP2040** (SBM ‚Äì Secondary Board Microcontroller) acts as the **slave**. It is dedicated to real-time control of low-level hardware components, such as driving the servo motor and interpreting incoming instructions from the master.

### üîÅ Serial Communication

The two boards communicate via a **UART (Serial) interface** using the following configuration:

- **Raspberry Pi TX (GPIO 14)** ‚Üí **Arduino RX (pin 1)**  
- **Raspberry Pi RX (GPIO 15)** ‚Üê **Arduino TX (pin 0)**

This full-duplex serial link enables:

- The **Raspberry Pi (master)** to send instructions like servo angles or movement triggers based on camera input.
- The **Arduino (slave)** to receive commands and execute precise control over hardware.
- **Optional feedback**: The Arduino can also send status messages or sensor feedback back to the Raspberry Pi when necessary.

This master-slave architecture promotes:

- **Modularity**, by separating high-level logic and low-level control.
- **Responsiveness**, with real-time actions handled by the microcontroller.
- **Scalability**, allowing for future hardware expansions without major rewrites.

The system is optimized for efficiency and robustness in fast-paced robotic challenges.

# üëÅÔ∏è Sense and Object Detection

Our robot uses **computer vision** to perceive its environment and make autonomous decisions.

### Vision System
We use the **Microsoft LifeCam HD-3000** webcam in combination with **OpenCV (Open Source Computer Vision Library)**, a powerful toolkit for real-time image processing. All image processing is handled on the **Raspberry Pi**, which interprets the camera feed and:

- Sends **steering commands** to the **Arduino Nano RP2040**, which controls the MG996R servo motor.
- Directly controls the **DC motor** through the **L298N motor driver**.

This setup enables the robot to:

- Detect and avoid **black walls** on the track.
- Identify and avoid **obstacles**, including **red and green blocks**.
- Recognize the **magenta parking spot** and perform parking maneuvers.
- Count **orange and blue lines** on the mat to track laps (12 sets of lines total), ensuring compliance with lap-counting requirements.


# ‚öîÔ∏è Challenge Strategies

## Open Challenge Strategy

The Open Challenge focuses on detecting colored lines‚Äîspecifically **orange** and **blue**‚Äîon the floor and reacting by steering the robot accordingly:

- The camera captures a Region of Interest (ROI) near the floor to detect these colored lines.
- HSV color filtering isolates orange and blue colors in the ROI.
- When an orange line is detected, the robot commands the servo to turn **120¬∞ to the right** and temporarily increases motor speed.
- When a blue line is detected, the robot commands the servo to turn **58¬∞ to the left** and also increases motor speed.
- If no colored line is detected, the servo centers at **90¬∞**, and the robot moves at a default speed.
- Turns last for a fixed duration (~1.3 seconds), after which the servo returns to center and speed reduces to default.
- Visual feedback is provided via OpenCV windows showing the camera feed and detected masks.
- The motor is continuously driven forward except when stopping is needed.
- This strategy allows the robot to smoothly follow colored paths by combining real-time color detection with timed servo steering commands.

## Obstacle Challenge Strategy

The Obstacle Challenge code relies on detecting colored blocks‚Äî**red** and **green**‚Äîusing the camera, and responding with precise servo movements to avoid collisions:

- The camera captures a region (ROI) where colored blocks appear.
- HSV filtering identifies red and green blocks.
- The program calculates the position (center X coordinate) and size (pixel area) of these blocks.
- When a red block is detected with enough size, the robot initiates a **right turn** by commanding the servo to angle **120¬∞**.
- When a green block is detected, it initiates a **left turn** with servo angle **58¬∞**.
- The robot **continues to turn until each block moves past a predefined horizontal limit** (an X-coordinate on the frame), ensuring the block is completely avoided before resuming a straight path.
   <div align="center">
  <img src="https://github.com/user-attachments/assets/7b70ce4a-0ba3-4e91-924a-d9df1eb91ae7" alt="Example image" width="300" />
</div>
- Turning state (`girando`) tracks if the robot is currently turning to prevent conflicting commands.           
- The robot uses a black line detection ROI to keep track and assist navigation while turning.
- Orange lines are detected to count how many have been crossed; the robot stops after detecting **12** orange lines, indicating the end of the course.
- The servo command is sent as an angle string to the Arduino, which moves the servo accordingly.
- The motor moves forward continuously unless stopped by the orange line count condition.
- The system uses visual markers and debug prints for easy monitoring.
- At the moment of parking it will identify the Magente parking lot and maneuver to do a parallel park.

This obstacle avoidance strategy combines color-based object detection with line following and a servo-actuated steering system to navigate safely and complete the obstacle course.

# `</>` Into the codes (code explanations)
## 1. **Open Challenge code**
- Import libraries
```python
import cv2
import numpy as np
import serial
import time
from gpiozero import Motor, PWMOutputDevice
```
These libraries provide access to the camera, matrix operations for image processing, serial communication with Arduino, timing functions, and motor control through the Raspberry Pi GPIO pins.

- Serial communication with Arduino
```python
arduino = serial.Serial("/dev/serial0", baudrate=9600, timeout=1)
time.sleep(2)
```
Initializes UART communication between Raspberry Pi and Arduino. The 2-second delay ensures the connection stabilizes before sending commands.

- Motor and speed configuration
```python
motor = Motor(forward=20, backward=21)
velocidad = PWMOutputDevice(12)
velocidad.value = 0.8
```
Sets up the movement motor and connects speed control via PWM. The motor is prepared to move forward, and a base speed of 80% is defined.

- Camera setup
```python
cap = cv2.VideoCapture(0)
cv2.namedWindow("Vista Completa", cv2.WINDOW_NORMAL)
cv2.resizeWindow("Vista Completa", 800, 600)
```
Starts the camera feed and creates a display window to visualize the robot's view in real time. Useful for debugging alignment and detecting colors correctly.

- Function to check color presence
```python
def detectar_color_linea(mask, umbral=1500):
    return cv2.countNonZero(mask) > umbral
  ```
This function evaluates if the number of white pixels in a binary mask exceeds a threshold. If so, it considers that color present in the frame.

- Function to detect orange or blue in the ROI
```python
def detectar_color_roi(roi_hsv):
    lower_blue = np.array([100, 55, 20])
    upper_blue = np.array([140, 255, 255])
    mask_blue = cv2.inRange(roi_hsv, lower_blue, upper_blue)

    lower_orange = np.array([0, 115, 139])
    upper_orange = np.array([25, 255, 255])
    mask_orange = cv2.inRange(roi_hsv, lower_orange, upper_orange)

    if detectar_color_linea(mask_orange):
        return "naranja", mask_orange
    elif detectar_color_linea(mask_blue):
        return "azul", mask_blue
    else:
        return None, None
  ```
Generates two binary masks for orange and blue using HSV thresholds. Based on the number of detected pixels, the function determines which color is present in the region of interest.

- Main control loop and behavior logic
```python
girando = False
inicio_giro = 0
direccion = 'C'
```
Initial variables to track whether the robot is turning, when the turn started, and the current servo direction: Centered (C), Left (L), or Right (R).
```python
try:
    while True:
        ret, frame = cap.read()
        if not ret:
            continue
```
Reads a frame from the camera. If the capture fails, it skips to the next loop iteration.
```python
        roi_inf = frame[355:405, :]
        hsv_inf = cv2.cvtColor(roi_inf, cv2.COLOR_BGR2HSV)
        color_inf, mask_inf = detectar_color_roi(hsv_inf)
 ```
- Defines a lower region of interest in the image where the color line is expected. Converts it to HSV for easier color detection.
```python
        if not girando:
            if color_inf == "naranja":
                print("üüß Orange detected ‚Üí sending '120'")
                arduino.write(b'120\n')
                velocidad.value = 1.0
                inicio_giro = time.time()
                girando = True
                direccion = 'R'
            elif color_inf == "azul":
                print("üîµ Blue detected ‚Üí sending '58'")
                arduino.write(b'58\n')
                velocidad.value = 1.0
                inicio_giro = time.time()
                girando = True
                direccion = 'L'
            else:
                print("‚ö™ No color detected ‚Üí centering servo (90)")
                arduino.write(b'90\n')
                direccion = 'C'
                velocidad.value = 0.8
 ```
When not turning, this logic decides how the servo should respond:
Orange: turn right (120¬∞)
Blue: turn left (58¬∞)
No color: return to center (90¬∞)
It also adjusts the speed and starts a timer if a turn was initiated.
```python
        else:
            if time.time() - inicio_giro >= 1.3:
                print("‚úÖ Turn duration complete ‚Üí sending '90'")
                arduino.write(b'90\n')
                velocidad.value = 0.8
                girando = False
                direccion = 'C'
```
If the robot is currently turning, this block checks if 1.3 seconds have passed. If so, the servo is returned to center and the robot exits turning mode.
```python
        motor.forward()
```
Keeps the robot moving forward regardless of servo direction.

- Visual feedback and debug tools
```python
        cv2.rectangle(frame, (0, 355), (640, 405), (255, 128, 0), 2)
        cv2.putText(frame, f"Dir: {direccion}", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
        cv2.imshow("Vista Completa", frame)

        if mask_inf is not None:
            cv2.imshow("ROI Inferior", mask_inf)
```
Draws a rectangle to visualize the region of interest and displays the current direction (L, R, C). Shows the processed binary mask to confirm color detection works as expected.
```python
   if cv2.waitKey(1) & 0xFF == ord('q'):
            break
```
Allows the user to exit the loop and end the program by pressing the q key.

- Cleanup and shutdown procedure
```python
finally:
    cap.release()
    cv2.destroyAllWindows()
    arduino.write(b'90\n')
    arduino.close()
    motor.stop()
```

Releases camera and OpenCV resources, centers the servo before exiting, closes the serial connection to Arduino, and stops the motor.
## 2. **Obstacle Challenge code**
Import libraries
```python
import cv2
import numpy as np
import serial
import time
from gpiozero import Motor, PWMOutputDevice
```
Handles camera access, image processing, numerical operations, motor control, and serial communication with Arduino.

- Serial connection setup
```python
arduino = serial.Serial("/dev/serial0", baudrate=9600, timeout=1)
time.sleep(2)
```
Establishes a UART connection between the Raspberry Pi and Arduino with a short delay to stabilize communication.

- Motor and speed setup
```python
motor = Motor(forward=20, backward=21)
velocidad = PWMOutputDevice(12)
velocidad.value = 0.85
```
Configures GPIO pins for motor direction and sets PWM speed to 85%.

- Camera setup
```python
cap = cv2.VideoCapture(0)
cv2.namedWindow("Vista Completa", cv2.WINDOW_NORMAL)
cv2.resizeWindow("Vista Completa", 800, 600)
```
Initializes the camera and creates a display window for visual feedback.

- Control and state variables
```python
lineas_detectadas = 0
umbral_linea = 1000
umbral_bloque = 800
linea_detectada = False
girando = False
direccion_giro = None

red_limit_x = 170
green_limit_x = 470
```
Tracks the state of line detection, block turns, and defines positional thresholds to determine when a block has passed.

- Helper function to find mask centroid
```python
def obtener_centro(mask):
    M = cv2.moments(mask)
    if M["m00"] != 0:
        cx = int(M["m10"] / M["m00"])
        return cx
    return None
```
Calculates the X-coordinate of the centroid of a binary mask. Used to know where a block is in the frame.

- Frame capture
```python
ret, frame = cap.read()
if not ret:
    continue
```
Reads the current frame from the camera. If the read fails, the loop skips to the next iteration.

- Block detection (red and green)
```python
roi_bloques = frame[200:320, :]
hsv_bloques = cv2.cvtColor(roi_bloques, cv2.COLOR_BGR2HSV)

# Red mask
lower_red1 = np.array([0, 120, 120])
upper_red1 = np.array([10, 255, 255])
lower_red2 = np.array([160, 120, 120])
upper_red2 = np.array([179, 255, 255])
mask_red = cv2.inRange(hsv_bloques, lower_red1, upper_red1) | cv2.inRange(hsv_bloques, lower_red2, upper_red2)

# Green mask
lower_green = np.array([85, 100, 100])
upper_green = np.array([100, 255, 255])
mask_green = cv2.inRange(hsv_bloques, lower_green, upper_green)

area_rojo = cv2.countNonZero(mask_red)
area_green = cv2.countNonZero(mask_green)
cx_rojo = obtener_centro(mask_red)
cx_green = obtener_centro(mask_green)
```
Detects red and green blocks based on HSV color ranges and calculates their positions and areas.

- Black line detection
```python
roi_nav = frame[160:280, :]
gray = cv2.cvtColor(roi_nav, cv2.COLOR_BGR2GRAY)
_, mask_black = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)

width = mask_black.shape[1]
third = width // 3
left_black = cv2.countNonZero(mask_black[:, 0:third])
center_black = cv2.countNonZero(mask_black[:, third:2*third])
right_black = cv2.countNonZero(mask_black[:, 2*third:3*third])
```
Uses a grayscale region to isolate the black navigation line and counts how many black pixels are in each section.

- Turning and navigation logic
```python
direction = 'C'
```
Initial direction is centered.

If turning based on block previously detected:
```python
if girando:
    if direccion_giro == 'R':
        if cx_rojo is not None and cx_rojo <= red_limit_x:
            girando = False
            direccion_giro = None
        elif right_black > 300:
            direction = 'C'
        else:
            direction = 'R'
    elif direccion_giro == 'L':
        if cx_green is not None and cx_green >= green_limit_x:
            girando = False
            direccion_giro = None
        elif left_black > 300:
            direction = 'C'
        else:
            direction = 'L'
```
If not currently turning:
```python
else:
    if area_rojo > umbral_bloque and cx_rojo is not None:
        direccion_giro = 'R'
        girando = True
        direction = 'R'
    elif area_green > umbral_bloque and cx_green is not None:
        direccion_giro = 'L'
        girando = True
        direction = 'L'
    else:
        min_black = min(left_black, center_black, right_black)
        if min_black == center_black:
            direction = 'C'
        elif min_black == left_black:
            direction = 'L'
        elif min_black == right_black:
            direction = 'R'
```
Controls the robot‚Äôs turning behavior based on detected blocks and black line regions.

- Orange line detection for stopping
```python
roi_linea = frame[400:480, :]
hsv = cv2.cvtColor(roi_linea, cv2.COLOR_BGR2HSV)
lower_orange = np.array([10, 150, 150])
upper_orange = np.array([25, 255, 255])
mask_linea = cv2.inRange(hsv, lower_orange, upper_orange)
area_linea = cv2.countNonZero(mask_linea)

if area_linea > umbral_linea and not linea_detectada and lineas_detectadas < 12:
    lineas_detectadas += 1
    linea_detectada = True
    time.sleep(1)

if area_linea <= umbral_linea:
    linea_detectada = False

if lineas_detectadas >= 12:
    direction = 'S'
    motor.stop()
else:
    motor.forward()
```
Counts the number of orange lines the robot crosses. Stops movement after 12 detections.

- Send servo angle to Arduino
```python
if direction == 'L':
    angulo = '58'
elif direction == 'C':
    angulo = '90'
elif direction == 'R':
    angulo = '120'
else:
    angulo = '90'

arduino.write((angulo + "\n").encode())
```
Maps the movement direction to a specific servo angle and sends the command to the Arduino for steering.

## 3. **Servo control code**
- Include libraries
```ino
#include <Servo.h>
#include <math.h>
```
The Servo.h library is included to control servo motors. math.h is included for compatibility but is not directly used in this code.

- Variable and object declarations
```ino
Servo miServo;
int pinServo = 2;
String comando = "";
unsigned long ultimoEnvio = 0;
const unsigned long intervalo = 100;
```
The miServo object is created to control the servo motor. pinServo sets the pin connected to the servo signal wire. The comando variable stores incoming serial commands as a string. ultimoEnvio and intervalo are reserved for timing tasks but are unused here.

- Setup function
```ino
void setup() {
  miServo.attach(pinServo);
  Serial1.begin(9600);
  Serial.begin(9600);
  delay(1000);

  Serial.println("Send angle (0 to 180) via Serial1 to move the servo.");
  miServo.write(90);
}
```
The servo is attached to the specified pin. UART serial communication (Serial1) is started at 9600 baud to talk with the Raspberry Pi, and USB serial (Serial) is started for debugging. The program waits one second for stability. A message with instructions is printed to the debug monitor. The servo is initialized at center position (90 degrees).

- Loop function: reading and processing commands
```ino
void loop() {
  while (Serial1.available() > 0) {
    char c = Serial1.read();

    if (c == '\n' || c == '\r') {
      comando.trim();

      if (comando.length() > 0) {
        int angulo = comando.toInt();

        if (angulo >= 0 && angulo <= 180) {
          miServo.write(angulo);
          Serial.print("Servo moved to ");
          Serial.print(angulo);
          Serial.println(" degrees");
        } else {
          Serial.println("Angle out of range (0‚Äì180)");
        }
      }

      comando = "";
    } else {
      comando += c;
    }
  }
}
```
The code reads incoming characters from the UART serial buffer one by one. It accumulates them into a command string until it detects a newline or carriage return character, signaling the end of a command. Then it trims whitespace from the command. If the command is not empty, it converts the string to an integer representing the servo angle. It checks if the angle is between 0 and 180 degrees. If valid, it moves the servo to that angle and prints a confirmation message. If invalid, it prints an error message. After processing, it clears the command buffer to prepare for the next command and continues looping.

## 4. **Run code when the raspberry turns on**
- Import libraries and modules
```python
from gpiozero import Button
from signal import pause
import subprocess
```
The script imports the Button class from gpiozero to handle GPIO pin inputs on the Raspberry Pi. The pause function from the signal module is imported to keep the script running and listening for events. The subprocess module allows the script to run external programs or scripts.

- Initialize button on GPIO pin 16
```python
boton = Button(16)
```
A Button object is created and linked to GPIO pin 16, which is physically connected to a push button on the Raspberry Pi. This button will trigger running the robot‚Äôs main program.

- Define function to run the main program
```python
def ejecutar_programa():
    print("Button pressed! Running the main program...")
    subprocess.run(["python3", "/home/diego/WRO_Ingeniero/otracosaahi.py"])
```
This function runs when the button is pressed. It prints a message to the terminal indicating the button press and then uses subprocess.run to execute another Python script (otracosaahi.py), which is the robot‚Äôs main control program. The path must be correct and the script must be executable.

- Link button press event to the function
```python
boton.when_pressed = ejecutar_programa
```
The button‚Äôs press event is connected to the ejecutar_programa function. When the button is pressed, this function will be called automatically.

- Indicate readiness and keep script running
```python
print("Waiting for the button to be pressed...")
pause()
```
Prints a message to inform the user that the system is ready and listening for the button press. The pause() function keeps the script running indefinitely so it can detect the button press event; without it, the script would exit immediately.

# üé• Video demonstration
Click down below for the demonstration of the first round of our robot.

[CLICK HERE!](https://youtu.be/aBIIU7W57JA?si=Zv62mgVx7OuttPh0)

---
**Stay tuned for updates as we continue to improve our robot's performance and capabilities!**

# References
- https://nerdvana.ro/wro-fe/
- https://markdownlivepreview.com/
- 

## üìú License

MIT License

Copyright (c) 2025 Ericka Ceballos

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


