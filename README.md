# TEKBOT WEST's readme <img src="https://upload.wikimedia.org/wikipedia/commons/a/ab/Flag_of_Panama.svg" alt="Bandera de Panamá" width="30"/>
<p align="center">
  <img src="https://github.com/user-attachments/assets/516d8dd3-5f5f-4bb0-b4f9-02e0fee0c09e" alt="TEKBOT (1)">
</p>


[![Instagram](https://img.shields.io/badge/Instagram-%23E9805F.svg?style=for-the-badge&logo=Instagram&logoColor=white)](https://www.instagram.com/tekbot_lab?utm_source=ig_web_button_share_sheet&igsh=ZDNlZDc0MzIxNw==)
[![Facebook](https://img.shields.io/badge/YouTube-%23E4445F.svg?style=for-the-badge&logo=Youtube&logoColor=white)](https://www.youtube.com/@TEKBOT_LAB)



# 🐙 Repo's folder structure/overview
```
📦 TEKBOT-WEST-WRO-FE
├── 📁 3D_printables # 3D models ready for printing robot components
├── 📁 schemes # Wiring and schematic diagram
├── 📁 src # Source code for robot control and challenge algorithms
├── 📁 team photos # Photos of the team 
├── 📁 vehicle photos # Pictures of the robot at different views
├── 📁 video # Video of testing competition runs
├── 📄 README.md # Main project documentation
```
---

<img width="1000" height="520" alt="AHHHHH_processed_by_imagy" src="https://github.com/user-attachments/assets/4d39ecf9-c464-4f2b-9efc-c3b949ed69be" />
<a href="https://github.com/kieviceb/TEKBOT-WEST-WRO-FE-PANAMA/tree/main/team%20photos">
  <img width="1000" height="2000" alt="BEHIND THE SCREENS (2)" src="https://github.com/user-attachments/assets/34d80203-9c0d-4e8b-a392-d2f8124f5f28" />
</a>


---
# Vehicle Photos 📸
<img width="1000" height="1500" alt="meet the team (2)" src="https://github.com/user-attachments/assets/be8bfb1d-6f9f-4342-a1d1-7f9fee7343f5" />

# Components 🧱
A list of all the electrical and mechanical components on the robot.

| <img src="https://github.com/user-attachments/assets/719a51d8-4b14-402d-a462-ba1e4b071c2c" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/3641b928-34c5-4d97-861c-fa08d40c9faa" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/3d5651d3-c8fe-4935-9561-6ca9d9c87a76" alt="Alt 1" width="200"/> | 
| :------------: |:-------------:| :------------:|
|[Raspberry Pi 5 - 8GB RAM x1](https://a.co/d/7e9fzE2)|[Microsoft LifeCam HD-3000 x1](https://a.co/d/66cNAOh)|[L298N motor driver x1](https://www.steren.com.pa/tarjeta-para-control-de-motores-cc-l298n.html)|
| <img src="https://github.com/user-attachments/assets/5b0ffc5d-ce02-4620-9849-15fdce566702" width="200"/> | <img src="https://github.com/user-attachments/assets/d4170adc-23b9-446f-bac0-1c50b966e00f" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/db07c349-4f9f-4661-8327-3c710a5d41c6" alt="Alt 1" width="200"/> |
| [Arduino NANO RP2040 connect x1](https://a.co/d/hI8sZ40) |[FUNDUINO kit chassis x1](https://a.co/d/fpJSHg1)|[Geekworm X1202 4-Cell 5V UPS Shiled+Active Cooler H505 x1](https://a.co/d/hs9rgxH) |
| <img src="https://github.com/user-attachments/assets/8002e73e-910a-462e-b991-5cd5c858e316" width="200"/> |<img src="https://github.com/user-attachments/assets/77157511-58ff-4ee8-9977-d3b53d906af6" alt="Alt 1" width="200"/>| <img src="https://github.com/user-attachments/assets/86d8bf70-708b-426f-896a-9283a74d13df" alt="Alt 1" width="200"/> |
|[Jumper wires](https://a.co/d/cw9IdJk)|[MG996R High Torque Metal Gear Servo x1](https://a.co/d/cRVAc0u)|[STEREN Li-ion 2800 mAh Rechargeable Battery x7](https://www.steren.com.pa/bateria-recargable-li-ion-2800-mah-tipo-18650-1.html)|
| <img src="https://github.com/user-attachments/assets/ff93515e-6ec1-41f5-be4c-ac25b1e24010" width="200"/> |<img src="https://github.com/user-attachments/assets/44a5bca6-2fb6-49b7-8374-93a03705a72b" alt="Alt 1" width="200"/>| <img src="https://github.com/user-attachments/assets/33ee1aaf-4750-4b80-978a-aab5d8d9adeb" alt="Alt 1" width="200"/> |
|[Ultrasonic Distance Sensor x3](https://a.co/d/cxbABTR)|[LEGO EV3 DC motor](https://ebay.us/m/6vxrYN)|[Cooling fan x3](https://a.co/d/frwMkoA)|
| <img src="https://github.com/user-attachments/assets/c4632267-e417-4f33-bfa0-a858d9f1e28e" width="200"/> |<img src="https://github.com/user-attachments/assets/dd5c7b13-b8ad-4aa0-9481-8411c9bf2b1a" alt="Alt 1" width="200"/>| <img src="https://github.com/user-attachments/assets/72f660f8-0134-4bb3-aa97-c8b0ae3c5f5a" alt="Alt 1" width="200"/> |
|[Mini breadboard x1](https://a.co/d/0logMX9)|[Push button x1](https://a.co/d/70cfCgl)|[ 10K ohm Resistor x1](https://a.co/d/dTNRWBD)|


# ⚡Circuit diagram

<img width="1920" height="1080" alt="Wiring diagram" src="https://github.com/user-attachments/assets/a8a37846-0950-4cb8-8dc3-2045f952b8c9" />

# Future Engineers Challenge Overview

The **WRO 2025 Future Engineers challenge** challenges teams to design and build a fully autonomous robot capable of navigating a dynamic and randomized racetrack. Using a combination of sensors, computer vision, and advanced control algorithms, the robot must adapt to changing obstacles, follow predefined driving rules, and demonstrate precise maneuvering skills.

### 📌 Competition Format

- **🏁 Open Challenge:**  
  The robot must complete **three (3) laps** around a track where obstacles and track elements are randomly placed, requiring real-time adaptation.

- **🚦 Obstacle Challenge:**  
  The robot must detect and respond correctly to randomly positioned colored markers:  
  - 🟥 **Red signs** → Robot must drive on the right side of the lane.  
  - 🟩 **Green signs** → Robot must drive on the left side of the lane.

  After completing the laps, the robot must find a designated parking zone and perform a precise **parallel parking maneuver** within a confined space, adding an additional technical challenge.

### 📑 Documentation Requirements

Each team is required to maintain a **public GitHub repository** documenting their engineering design process, technical decisions, robot design, and source code. This encourages transparency, collaboration, and learning within the robotics community.

### 🏆 Scoring & Evaluation

Teams are evaluated based on their robot’s **accuracy**, **speed**, and the quality of their **technical documentation**. Points are awarded to teams that effectively balance performance, adaptability to randomized conditions, and innovation in their approach. This challenge promotes not only technical skills in robotics and programming but also problem-solving, teamwork, and creative engineering.
> [!WARNING]
>
> We noticed a translation misunderstanding regarding the rules, at the original english version it says
> that the robot starting within the parking lot is 7 points, but in the spanish version states that the robot should be on
> In the parking lot, not specifying if before or after the challenge is done, but taking as reference the original english version
> the robot starting on the parking lot can score 7 points.
>
<img width="653" height="186" alt="meet the team (3)" src="https://github.com/user-attachments/assets/3d4dfe50-6bb6-4aca-be4a-6e9f3429dde8" />

---

> [!NOTE]
> For detailed rules and regulations (PANAMA ONLY), please refer to the official WRO Panama 2025 Future Engineers document:  
> [WRO 2025 Future Engineers Rules (PDF)](https://fundesteam.nyc3.cdn.digitaloceanspaces.com/FutureEngineers/WRO-2025-FE-Reglas%20Generales.pdf)

<br>


# ⚙️ Mobility Management

### Movement
- **LEGO EV3 Large Motor** driven by an L298N H-bridge on the Arduino Nano RP2040, powered by a 3×18650 Li-ion pack (≈11.1 V) for high torque.
- PWM speed control (pin D3) and direction pins (D4/D5), with automatic halt if HC-SR04 front distance < threshold.
- Receives speed & direction commands over Serial1 from the Raspberry Pi.

### Steering
- **MG996R metal-gear servo** in an Ackermann linkage for accurate, repeatable turns.
- Servo angles (60° left, 90° center, 120° right) sent as ASCII strings over Serial1 and output via PWM on D9.
- Combines ultrasonic PD wall-following and IMU yaw-rate curve detection for smooth autonomous steering.


# 🔋 Power Management

Our robot uses a streamlined power system for stable, efficient energy distribution:

- **Geekworm UPS Module**  
  All computing units (Raspberry Pi & Arduino Nano RP2040) are powered directly from the Geekworm Raspberry Pi Wide Input Voltage UPS, providing regulated 5 V output and battery backup—no external power bank needed.

- **Servo Power**  
  The MG996R steering servo draws its 5 V supply from the UPS module, ensuring stable, synchronized operation.

- **Camera Power**  
  The Microsoft LifeCam HD-3000 connects via USB to the Raspberry Pi and is powered through the UPS, eliminating separate camera power sources.

- **DC Motor Power**  
  The L298N H-bridge and DC motor are driven by a dedicated pack of three 18650 Li-ion cells in series (≈11.1 V), delivering the higher voltage and current the motor requires.

This setup reduces weight, simplifies cabling, and guarantees reliable power under all operating conditions.  


# 📡 Robot Communication

Our robot implements a structured communication system between its two core processing units to ensure synchronized and reliable operation:

- The **Raspberry Pi** (SBC – Single Board Computer) acts as the **master**. It is responsible for high-level tasks such as image processing, object detection, strategy decision-making, and general system coordination.

- The **Arduino Nano RP2040** (SBM – Secondary Board Microcontroller) acts as the **slave**. It is dedicated to real-time control of low-level hardware components, such as driving the servo motor and interpreting incoming instructions from the master.

### 🔁 Serial Communication

The two boards communicate via a **UART (Serial) interface** using the following configuration:

- **Raspberry Pi TX (GPIO 14)** → **Arduino RX (pin 1)**  
- **Raspberry Pi RX (GPIO 15)** ← **Arduino TX (pin 0)**

This full-duplex serial link enables:

- The **Raspberry Pi (master)** to send instructions like servo angles or movement triggers based on camera input.
- The **Arduino (slave)** to receive commands and execute precise control over hardware.
- **Optional feedback**: The Arduino can also send status messages or sensor feedback back to the Raspberry Pi when necessary.

This master-slave architecture promotes:

- **Modularity**, by separating high-level logic and low-level control.
- **Responsiveness**, with real-time actions handled by the microcontroller.
- **Scalability**, allowing for future hardware expansions without major rewrites.

The system is optimized for efficiency and robustness in fast-paced robotic challenges.

# 👁️ Sense and Object Detection

Our robot relies on a combination of vision, ultrasonic sensing, and inertial measurement to understand its environment and make driving decisions.

### Vision System  
We use the Microsoft LifeCam HD-3000 with OpenCV on the Raspberry Pi. The Pi processes the camera feed to:  
- Detect **red** and **green blocks** for obstacle avoidance.  
- Recognize the **magenta parking spot** to initiate the parking routine.  
- Send steering and speed commands to the Arduino Nano RP2040 over Serial.

### Ultrasonic Wall Detection  
The Arduino Nano RP2040 reads three HC-SR04 ultrasonic sensors (left, center, right) to:  
- Measure distances to **black walls** on either side and in front.  
- Trigger emergency avoidance maneuvers when walls are too close.

### IMU-Based Curve Detection  
An IMU on the Arduino provides:  
- Precise yaw (Z-axis) rate measurements.  
- Automatic detection of each curve when the yaw rate exceeds a threshold.  
- Curve counting (stop after **12** curves) and smooth turn control.

This multi-sensor approach ensures robust performance: vision handles colored block and parking detection, ultrasonics handle wall avoidance, and the IMU guarantees accurate turn detection and counting.  

# ⚔️ Challenge Strategies
## Open Challenge Strategy

- **Start Command**  
  Wait for `'s'` on Serial1 before beginning navigation.

- **Ultrasonic Sensing**  
  Continuously read left, center and right HC-SR04 sensors for obstacle distances.

- **Front Obstacle Handling**  
  If center distance ≤ FRONT_MIN, halt motor; otherwise drive at fixed PWM speed.

- **Emergency Side Avoidance**  
  If left or right distance ≤ SIDE_MIN, immediately steer hard away (servo to 120° or 60°).

- **PD Steering Control**  
  When no emergency, compute error = dR − dL and derivative, apply Kp/Kd to adjust servo within ±30° deadzone around 90°.

- **Curve Detection via IMU**  
  Read MPU6050 gyro Z-axis; when |ωZ| > 30°/s detect a new turn, increment curveCount and prevent multiple counts during one turn.

- **Completion Condition**  
  Stop motor and center servo once 12 curves have been counted; remain halted.

- **Serial Feedback**  
  Print “Curve #n” and status messages over Serial1 for real-time monitoring.

## Obstacle Challenge Strategy

- **ROI & LAB Masking**  
  Convert the ROI to LAB and extract masks for red, green, orange (and black guide lines), boosting precision and efficiency.

- **Contour Detection**  
  Find contours on each LAB mask to compute block centroids and areas.
![WhatsApp Image 2025-07-31 at 20 11 59_a4aa4e94](https://github.com/user-attachments/assets/e9547dd8-7004-4965-af65-36867bd807ac)
- **Block Turns**  
  - **Red →** right turn (servo 120°)  
  - **Green →** left turn (servo 58°)  
  Hold the command until the block exits the frame.

- **Line Tracking**  
  Use a black-line LAB mask to keep alignment during and after turns.

- **Stage Counting**  
  Increment on each orange line detected; stop after **12** crossings.

- **Serial Steering & Motor**  
  Send `S<angle>` over Serial to Arduino; motor runs forward continuously unless the final stop is reached.

- **Final Parking**  
  Detect magenta markers in LAB space to initiate a parallel-parking routine.


# `</>` Into the codes (code explanations)
## 1. **Open Challenge code**
- **Include Libraries**
  ```cpp
  #include <Wire.h>
  #include <MPU6050.h>
  #include <Servo.h>
These headers let us use I²C (Wire) to communicate with the MPU6050 IMU, access the IMU’s functions, and drive a steering servo.
-Define Pins & Constants
```cpp
// HC-SR04 ultrasonic sensors
const int TRIG_LEFT   = 6;
const int ECHO_LEFT   = 7;
const int TRIG_CENT   = 8;
const int ECHO_CENT   = 9;
const int TRIG_RIGHT  = 10;
const int ECHO_RIGHT  = 11;

// Steering servo and motor H-bridge
const int SERVO_PIN   = 2;
const int ENB         = 3;
const int IN3         = 4;
const int IN4         = 5;

// PD control gains
const float Kp = 0.5;
const float Kd = 0.1;

// Safety thresholds (cm)
const float SIDE_MIN_LEFT  = 17.0;
const float SIDE_MIN_RIGHT = 16.0;
const float FRONT_MIN      = 16.0;

// Servo limits
const int SERVO_CENTER    = 90;
const int SERVO_MAX_LEFT  = 60;
const int SERVO_MAX_RIGHT = 120;
const int SERVO_DEADZONE  = 30;

// Motor speed (0–255 PWM)
const int MOTOR_SPEED = 200;
```
These constants map the sensor and actuator pins, set the PD controller gains, safety distance thresholds, servo angle limits, and the fixed motor speed.
-Global Objects & State
```cpp
Servo    steeringServo;
MPU6050  imu;

bool          started    = false;  // Has 's' been received on Serial1?
int           curveCount = 0;      // Number of curves detected
bool          turning    = false;  // Currently in a turn?
float         prevError  = 0;
unsigned long prevTime;
```
We create the servo and IMU objects, plus variables to track whether the robot has started, how many curves it’s made (via gyro), the turning state, and timing for the PD controller.

-Setup Function
```cpp
void setup() {
  // 1) Serial1 for start command
  Serial1.begin(115200);
  Serial1.println("Waiting for 's' to start…");

  // 2) Initialize IMU over I²C
  Wire.begin();
  imu.initialize();
  if (!imu.testConnection()) {
    Serial1.println("IMU not found!");
    while(true); // Halt if IMU missing
  }
  Serial1.println("IMU initialized.");

  // 3) Configure sensor & actuator pins
  pinMode(TRIG_LEFT, OUTPUT);  pinMode(ECHO_LEFT, INPUT);
  pinMode(TRIG_CENT, OUTPUT);  pinMode(ECHO_CENT, INPUT);
  pinMode(TRIG_RIGHT, OUTPUT); pinMode(ECHO_RIGHT, INPUT);

  steeringServo.attach(SERVO_PIN);
  steeringServo.write(SERVO_CENTER);

  pinMode(ENB, OUTPUT);
  pinMode(IN3, OUTPUT);
  pinMode(IN4, OUTPUT);
  digitalWrite(IN3, HIGH); // forward
  digitalWrite(IN4, LOW);

  prevTime = micros();
}
```
-Serial1 listens for 's' to begin
-IMU is initialized and tested
-Pins for sensors, servo, and motor are configured and centered
Main Loop
```cpp
void loop() {
  // A) Wait for 's' on Serial1
  if (!started) {
    if (Serial1.available() && Serial1.read() == 's') {
      started = true;
      Serial1.println("Starting navigation…");
    } else {
      return; // idle until start
    }
  }

  // B) Read distances
  float dL = readUltrasonic(TRIG_LEFT,  ECHO_LEFT);
  float dC = readUltrasonic(TRIG_CENT,  ECHO_CENT);
  float dR = readUltrasonic(TRIG_RIGHT, ECHO_RIGHT);

  // C) Front obstacle → stop or go
  if (dC <= FRONT_MIN)        analogWrite(ENB, 0);
  else                        analogWrite(ENB, MOTOR_SPEED);

  // D) Emergency side avoidance or PD steering
  if (dL <= SIDE_MIN_LEFT)    steeringServo.write(SERVO_MAX_RIGHT);
  else if (dR <= SIDE_MIN_RIGHT) steeringServo.write(SERVO_MAX_LEFT);
  else {
    unsigned long now = micros();
    float dt = (now - prevTime) / 1e6;
    prevTime = now;
    float error = dR - dL;
    float dErr  = (error - prevError) / dt;
    prevError   = error;
    int delta = constrain(int(Kp*error + Kd*dErr),
                          -SERVO_DEADZONE, SERVO_DEADZONE);
    steeringServo.write(SERVO_CENTER + delta);
  }

  // E) Curve detection via IMU gyro Z-axis
  float gyroZ = imu.getRotationZ() / 131.0;  // °/s
  const float TURN_THRESHOLD = 30.0;
  if (abs(gyroZ) > TURN_THRESHOLD) {
    if (!turning) {
      turning = true;
      curveCount++;
      Serial1.print("Curve #"); Serial1.println(curveCount);
    }
  } else {
    turning = false;
  }

  // F) Stop after 12 curves
  if (curveCount >= 12) {
    analogWrite(ENB, 0);
    steeringServo.write(SERVO_CENTER);
    Serial1.println("12 curves reached—stopping.");
    while(true);
  }

  delay(50); // ~20 Hz
}
```
-Start check: waits for 's'
-Read sensors: left, center, right
-Front control: stop or run motor
-Side avoidance & PD steering: emergency or smooth control
-Curve detection: increment count when gyro Z exceeds threshold
-Stop condition: halt when 12 curves detected
-Utility: Ultrasonic Read
```cpp
float readUltrasonic(int trigPin, int echoPin) {
  digitalWrite(trigPin, LOW);
  delayMicroseconds(2);
  digitalWrite(trigPin, HIGH);
  delayMicroseconds(10);
  digitalWrite(trigPin, LOW);
  long duration = pulseIn(echoPin, HIGH, 30000);
  if (duration == 0) return 300; 
  return duration * 0.0343 / 2.0;  // cm
}
```
Triggers the HC-SR04 sensor, measures echo pulse width, and converts it to distance in centimeters.

## 2. **Obstacle Challenge code**
Import libraries
```python
import cv2
import numpy as np
import serial
import time
from gpiozero import Motor, PWMOutputDevice
```
Handles camera access, image processing, numerical operations, motor control, and serial communication with Arduino.

- Serial connection setup
```python
arduino = serial.Serial("/dev/serial0", baudrate=9600, timeout=1)
time.sleep(2)
```
Establishes a UART connection between the Raspberry Pi and Arduino with a short delay to stabilize communication.

- Motor and speed setup
```python
motor = Motor(forward=20, backward=21)
velocidad = PWMOutputDevice(12)
velocidad.value = 0.85
```
Configures GPIO pins for motor direction and sets PWM speed to 85%.

- Camera setup
```python
cap = cv2.VideoCapture(0)
cv2.namedWindow("Vista Completa", cv2.WINDOW_NORMAL)
cv2.resizeWindow("Vista Completa", 800, 600)
```
Initializes the camera and creates a display window for visual feedback.

- Control and state variables
```python
lineas_detectadas = 0
umbral_linea = 1000
umbral_bloque = 800
linea_detectada = False
girando = False
direccion_giro = None

red_limit_x = 170
green_limit_x = 470
```
Tracks the state of line detection, block turns, and defines positional thresholds to determine when a block has passed.

- Helper function to find mask centroid
```python
def obtener_centro(mask):
    M = cv2.moments(mask)
    if M["m00"] != 0:
        cx = int(M["m10"] / M["m00"])
        return cx
    return None
```
Calculates the X-coordinate of the centroid of a binary mask. Used to know where a block is in the frame.

- Frame capture
```python
ret, frame = cap.read()
if not ret:
    continue
```
Reads the current frame from the camera. If the read fails, the loop skips to the next iteration.

- Block detection (red and green)
```python
roi_bloques = frame[200:320, :]
hsv_bloques = cv2.cvtColor(roi_bloques, cv2.COLOR_BGR2HSV)

# Red mask
lower_red1 = np.array([0, 120, 120])
upper_red1 = np.array([10, 255, 255])
lower_red2 = np.array([160, 120, 120])
upper_red2 = np.array([179, 255, 255])
mask_red = cv2.inRange(hsv_bloques, lower_red1, upper_red1) | cv2.inRange(hsv_bloques, lower_red2, upper_red2)

# Green mask
lower_green = np.array([85, 100, 100])
upper_green = np.array([100, 255, 255])
mask_green = cv2.inRange(hsv_bloques, lower_green, upper_green)

area_rojo = cv2.countNonZero(mask_red)
area_green = cv2.countNonZero(mask_green)
cx_rojo = obtener_centro(mask_red)
cx_green = obtener_centro(mask_green)
```
Detects red and green blocks based on HSV color ranges and calculates their positions and areas.

- Black line detection
```python
roi_nav = frame[160:280, :]
gray = cv2.cvtColor(roi_nav, cv2.COLOR_BGR2GRAY)
_, mask_black = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)

width = mask_black.shape[1]
third = width // 3
left_black = cv2.countNonZero(mask_black[:, 0:third])
center_black = cv2.countNonZero(mask_black[:, third:2*third])
right_black = cv2.countNonZero(mask_black[:, 2*third:3*third])
```
Uses a grayscale region to isolate the black navigation line and counts how many black pixels are in each section.

- Turning and navigation logic
```python
direction = 'C'
```
Initial direction is centered.

If turning based on block previously detected:
```python
if girando:
    if direccion_giro == 'R':
        if cx_rojo is not None and cx_rojo <= red_limit_x:
            girando = False
            direccion_giro = None
        elif right_black > 300:
            direction = 'C'
        else:
            direction = 'R'
    elif direccion_giro == 'L':
        if cx_green is not None and cx_green >= green_limit_x:
            girando = False
            direccion_giro = None
        elif left_black > 300:
            direction = 'C'
        else:
            direction = 'L'
```
If not currently turning:
```python
else:
    if area_rojo > umbral_bloque and cx_rojo is not None:
        direccion_giro = 'R'
        girando = True
        direction = 'R'
    elif area_green > umbral_bloque and cx_green is not None:
        direccion_giro = 'L'
        girando = True
        direction = 'L'
    else:
        min_black = min(left_black, center_black, right_black)
        if min_black == center_black:
            direction = 'C'
        elif min_black == left_black:
            direction = 'L'
        elif min_black == right_black:
            direction = 'R'
```
Controls the robot’s turning behavior based on detected blocks and black line regions.

- Orange line detection for stopping
```python
roi_linea = frame[400:480, :]
hsv = cv2.cvtColor(roi_linea, cv2.COLOR_BGR2HSV)
lower_orange = np.array([10, 150, 150])
upper_orange = np.array([25, 255, 255])
mask_linea = cv2.inRange(hsv, lower_orange, upper_orange)
area_linea = cv2.countNonZero(mask_linea)

if area_linea > umbral_linea and not linea_detectada and lineas_detectadas < 12:
    lineas_detectadas += 1
    linea_detectada = True
    time.sleep(1)

if area_linea <= umbral_linea:
    linea_detectada = False

if lineas_detectadas >= 12:
    direction = 'S'
    motor.stop()
else:
    motor.forward()
```
Counts the number of orange lines the robot crosses. Stops movement after 12 detections.

- Send servo angle to Arduino
```python
if direction == 'L':
    angulo = '58'
elif direction == 'C':
    angulo = '90'
elif direction == 'R':
    angulo = '120'
else:
    angulo = '90'

arduino.write((angulo + "\n").encode())
```
Maps the movement direction to a specific servo angle and sends the command to the Arduino for steering.

## 3. **Servo control code**
- Include libraries
```ino
#include <Servo.h>
#include <math.h>
```
The Servo.h library is included to control servo motors. math.h is included for compatibility but is not directly used in this code.

- Variable and object declarations
```ino
Servo miServo;
int pinServo = 2;
String comando = "";
unsigned long ultimoEnvio = 0;
const unsigned long intervalo = 100;
```
The miServo object is created to control the servo motor. pinServo sets the pin connected to the servo signal wire. The comando variable stores incoming serial commands as a string. ultimoEnvio and intervalo are reserved for timing tasks but are unused here.

- Setup function
```ino
void setup() {
  miServo.attach(pinServo);
  Serial1.begin(9600);
  Serial.begin(9600);
  delay(1000);

  Serial.println("Send angle (0 to 180) via Serial1 to move the servo.");
  miServo.write(90);
}
```
The servo is attached to the specified pin. UART serial communication (Serial1) is started at 9600 baud to talk with the Raspberry Pi, and USB serial (Serial) is started for debugging. The program waits one second for stability. A message with instructions is printed to the debug monitor. The servo is initialized at center position (90 degrees).

- Loop function: reading and processing commands
```ino
void loop() {
  while (Serial1.available() > 0) {
    char c = Serial1.read();

    if (c == '\n' || c == '\r') {
      comando.trim();

      if (comando.length() > 0) {
        int angulo = comando.toInt();

        if (angulo >= 0 && angulo <= 180) {
          miServo.write(angulo);
          Serial.print("Servo moved to ");
          Serial.print(angulo);
          Serial.println(" degrees");
        } else {
          Serial.println("Angle out of range (0–180)");
        }
      }

      comando = "";
    } else {
      comando += c;
    }
  }
}
```
The code reads incoming characters from the UART serial buffer one by one. It accumulates them into a command string until it detects a newline or carriage return character, signaling the end of a command. Then it trims whitespace from the command. If the command is not empty, it converts the string to an integer representing the servo angle. It checks if the angle is between 0 and 180 degrees. If valid, it moves the servo to that angle and prints a confirmation message. If invalid, it prints an error message. After processing, it clears the command buffer to prepare for the next command and continues looping.

## 4. **Run code when the raspberry turns on**
- Import libraries and modules
```python
from gpiozero import Button
from signal import pause
import subprocess
```
The script imports the Button class from gpiozero to handle GPIO pin inputs on the Raspberry Pi. The pause function from the signal module is imported to keep the script running and listening for events. The subprocess module allows the script to run external programs or scripts.

- Initialize button on GPIO pin 16
```python
boton = Button(16)
```
A Button object is created and linked to GPIO pin 16, which is physically connected to a push button on the Raspberry Pi. This button will trigger running the robot’s main program.

- Define function to run the main program
```python
def ejecutar_programa():
    print("Button pressed! Running the main program...")
    subprocess.run(["python3", "/home/diego/WRO_Ingeniero/otracosaahi.py"])
```
This function runs when the button is pressed. It prints a message to the terminal indicating the button press and then uses subprocess.run to execute another Python script (otracosaahi.py), which is the robot’s main control program. The path must be correct and the script must be executable.

- Link button press event to the function
```python
boton.when_pressed = ejecutar_programa
```
The button’s press event is connected to the ejecutar_programa function. When the button is pressed, this function will be called automatically.

- Indicate readiness and keep script running
```python
print("Waiting for the button to be pressed...")
pause()
```
Prints a message to inform the user that the system is ready and listening for the button press. The pause() function keeps the script running indefinitely so it can detect the button press event; without it, the script would exit immediately.

# 🎥 Video demonstration
[![TEKBOT (2)](https://github.com/user-attachments/assets/4f9f93a7-745f-4261-8274-8bc7922caef0)](https://www.youtube.com/watch?v=aBIIU7W57JA)
---
**Stay tuned for updates as we continue to improve our robot's performance and capabilities!**

# References
- https://nerdvana.ro/wro-fe/
- https://markdownlivepreview.com/
- https://docs.opencv.org/3.4/da/d97/tutorial_threshold_inRange.html

# Shout-Outs

A huge thank you to everyone who made this project possible:

- **The Sutherland Family**  
  For sharing their technical know-how, sourcing crucial parts, and helping with all of our 3D printing needs.

- **Ericka’s Family**  
  For opening up their living room as our track space and pitching in to build the surrounding walls.

- **The Hidalgo Family**  
  For generously donating the printed track mat that serves as our competition surface.

- **Diego’s Family**  
  For welcoming us into their home and providing a comfortable space for our team meetings and build sessions.

We couldn’t have done it without your support—thank you for being an integral part of our journey!

# 📜 License

MIT License

Copyright (c) 2025 Ericka Ceballos

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



